{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import modules as qmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an object for the Video class\n",
    "Video = qmod.Video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of the video is 124\n['/mnt/video_samples/Video1.mp4', '/mnt/video_samples/Video2.mp4']\nLength of the videos are {'/mnt/video_samples/Video1.mp4': 124, '/mnt/video_samples/Video2.mp4': 124}\n"
    }
   ],
   "source": [
    "# Length of a single video file\n",
    "length = Video.video_length(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Length of the video is\", length)\n",
    "\n",
    "# Length of a video folder\n",
    "length = Video.video_length(path='/mnt/video_samples')\n",
    "print(\"Length of the videos are\", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Resolution of the video: 1280p\nResolution of the videos: {'/mnt/video_samples/Video1.mp4': '1280p', '/mnt/video_samples/Video2.mp4': '1280p'}\n"
    }
   ],
   "source": [
    "# Resolution of the video\n",
    "resolution = Video.resolution(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Resolution of the video:\", resolution)\n",
    "\n",
    "# Resolution of the video folder\n",
    "resolution = Video.resolution(path='/mnt/video_samples')\n",
    "print(\"Resolution of the videos:\", resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Format of the video is .mp4\nFormat of the videos are {'/mnt/video_samples/Video1.mp4': '.mp4', '/mnt/video_samples/Video2.mp4': '.mp4'}\n"
    }
   ],
   "source": [
    "# Format of a single video file\n",
    "format = Video.video_format(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Format of the video is\", format)\n",
    "\n",
    "# Length of a video folder\n",
    "format = Video.video_format(path='/mnt/video_samples')\n",
    "print(\"Format of the videos are\", format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Audio file not found!!!\nExtracting audio from video\nMoviePy - Writing audio in audio_files/Video2_Audio.mp3\nchunk:  97%|█████████▋| 2574/2648 [00:01<00:00, 1825.76it/s, now=None]MoviePy - Done.\nBitrate of the video is 1124\nAudio file not found!!!\nExtracting audio from video\nMoviePy - Writing audio in audio_files/Video1_Audio.mp3\nchunk:  94%|█████████▍| 2501/2649 [00:01<00:00, 1765.81it/s, now=None]MoviePy - Done.\nBitrate of the videos are {'Video1': 1123, 'Video2': 1124}\n"
    }
   ],
   "source": [
    "# Bitrate of a single video file\n",
    "bitrate = Video.bitrate(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Bitrate of the video is\", bitrate)\n",
    "\n",
    "# Length of a video folder\n",
    "bitrate = Video.bitrate(path='/mnt/video_samples')\n",
    "print(\"Bitrate of the videos are\", bitrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using cache found in /home/ubuntu/.cache/torch/hub/ultralytics_yolov5_master\nYOLOv5 🚀 2022-6-1 Python-3.6.10 torch-1.10.1+cu102 CPU\n\nDownloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\nPython 3.7.0 required by YOLOv5, but Python 3.6.10 is currently installed\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0.00/14.1M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7289c21ee9fe495284b8911a3f31fdca"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\nFusing layers... \nYOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\nAdding AutoShape... \nUsing cache found in /home/ubuntu/.cache/torch/hub/ultralytics_yolov5_master\nYOLOv5 🚀 2022-6-1 Python-3.6.10 torch-1.10.1+cu102 CPU\n\nFusing layers... \nObjects detected in the video are: {'keyboard', 'cell phone', 'chair', 'toilet', 'umbrella', 'traffic light', 'tie', 'cup', 'dog', 'snowboard', 'kite', 'bottle', 'frisbee', 'microwave', 'refrigerator', 'tv', 'cat', 'book', 'bird', 'car', 'person', 'potted plant', 'remote'}\nPython 3.7.0 required by YOLOv5, but Python 3.6.10 is currently installed\nYOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\nAdding AutoShape... \nUsing cache found in /home/ubuntu/.cache/torch/hub/ultralytics_yolov5_master\nYOLOv5 🚀 2022-6-1 Python-3.6.10 torch-1.10.1+cu102 CPU\n\nFusing layers... \nYOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\nAdding AutoShape... \nPython 3.7.0 required by YOLOv5, but Python 3.6.10 is currently installed\nObjects detected in the videos are: {'/mnt/video_samples/Video1.mp4': {'keyboard', 'cell phone', 'chair', 'couch', 'toothbrush', 'umbrella', 'tie', 'cup', 'dining table', 'laptop', 'dog', 'boat', 'bear', 'bottle', 'fork', 'frisbee', 'microwave', 'refrigerator', 'tv', 'cake', 'sink', 'vase', 'bowl', 'banana', 'book', 'oven', 'car', 'person', 'wine glass'}, '/mnt/video_samples/Video2.mp4': {'keyboard', 'cell phone', 'chair', 'toilet', 'umbrella', 'traffic light', 'tie', 'cup', 'dog', 'snowboard', 'kite', 'bottle', 'frisbee', 'microwave', 'refrigerator', 'tv', 'cat', 'book', 'bird', 'car', 'person', 'potted plant', 'remote'}}\n"
    }
   ],
   "source": [
    "objects = Video.detect_objects(path='/mnt/video_samples/Video2.mp4', modelname='yolov5s')\n",
    "print(\"Objects detected in the video are:\", objects)\n",
    "\n",
    "objects = Video.detect_objects(path='/mnt/video_samples', modelname='yolov5s')\n",
    "print(\"Objects detected in the videos are:\", objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Frame rate of the video is 29\nFrame rate of the videos are {'/mnt/video_samples/Video1.mp4': 29, '/mnt/video_samples/Video2.mp4': 29}\n"
    }
   ],
   "source": [
    "# Frame rate of a single video file\n",
    "framerate = Video.framerate(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Frame rate of the video is\", framerate)\n",
    "\n",
    "# Frame Rate of a video folder\n",
    "framerate = Video.framerate(path='/mnt/video_samples')\n",
    "print(\"Frame rate of the videos are\", framerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Brightness of the video is 123.83800043728469\nBrightness of the videos are {'/mnt/video_samples/Video1.mp4': 129.57219099077565, '/mnt/video_samples/Video2.mp4': 123.83800043728469}\n"
    }
   ],
   "source": [
    "# Brightness of a single video file\n",
    "brightness = Video.brightness(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Brightness of the video is\", brightness)\n",
    "\n",
    "# Brightness of a video folder\n",
    "brightness = Video.brightness(path='/mnt/video_samples')\n",
    "print(\"Brightness of the videos are\", brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time created of the video is 2021-03-27T22:07:39.000000Z\nTime created of the videos are {'/mnt/video_samples/Video1.mp4': '2021-03-07T14:48:14.000000Z', '/mnt/video_samples/Video2.mp4': '2021-03-27T22:07:39.000000Z'}\n"
    }
   ],
   "source": [
    "# Time created of a single video file\n",
    "time = Video.time_created(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Time created of the video is\", time)\n",
    "\n",
    "# Time created of a video folder\n",
    "time = Video.time_created(path='/mnt/video_samples')\n",
    "print(\"Time created of the videos are\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Percentage of artifacts present of the video is 100.0\nPercentage of artifacts present of the videos are {'/mnt/video_samples/Video1.mp4': 100.0, '/mnt/video_samples/Video2.mp4': 100.0}\n"
    }
   ],
   "source": [
    "# Percentage of artifacts present of a single video file\n",
    "artifact = Video.check_artifacts(path='/mnt/video_samples/Video2.mp4')\n",
    "print(\"Percentage of artifacts present of the video is\", artifact)\n",
    "\n",
    "# Percentage of artifacts present of a video folder\n",
    "artifact = Video.check_artifacts(path='/mnt/video_samples')\n",
    "print(\"Percentage of artifacts present of the videos are\", artifact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('bump': conda)",
   "language": "python",
   "name": "python361064bitbumpconda2e3dca47b9664c429dba6db425ce8034"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10514fac1101a9004193c1241e8a1e65ce5546b0de4b301a6547d5f4a83192d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}